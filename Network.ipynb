{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_DICT=dict()\n",
    "NO_DICT=dict()\n",
    "for i in range(26):\n",
    "    CHAR_DICT[chr(97+i)]=i\n",
    "    NO_DICT[i]=chr(97+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d': 3, 'k': 10, 'z': 25, 'v': 21, 's': 18, 'w': 22, 't': 19, 'n': 13, 'q': 16, 'c': 2, 'x': 23, 'o': 14, 'e': 4, 'r': 17, 'g': 6, 'f': 5, 'y': 24, 'a': 0, 'u': 20, 'l': 11, 'j': 9, 'i': 8, 'm': 12, 'b': 1, 'h': 7, 'p': 15} {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z'}\n"
     ]
    }
   ],
   "source": [
    "print(CHAR_DICT,NO_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def resize_image(image):\n",
    "    height_inc=((28-image.shape[0])//2)\n",
    "    width_inc=math.floor((28-image.shape[1])/2)\n",
    "    #print(width_inc,image.shape[1])\n",
    "    BLUE=[0,0,0]\n",
    "    constant=cv2.copyMakeBorder(image,height_inc,height_inc,width_inc,width_inc,cv2.BORDER_ISOLATED,value=BLUE)\n",
    "    \n",
    "    if(constant.shape[1]<28):\n",
    "        constant=resize_image(constant[:,:26])\n",
    "    if(constant.shape[0]<28):\n",
    "        constant=resize_image(constant[0:26,:])\n",
    "    return constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels():\n",
    "    file=open('labels.txt','r')\n",
    "    all_lines=file.readlines()\n",
    "    characters=[]\n",
    "    for i in range(0,len(all_lines),2):\n",
    "        characters+=all_lines[i][:-1].split(' ')\n",
    "    labels=[]\n",
    "    #print(characters)\n",
    "    for i in range(len(characters)-1):\n",
    "        labels.append(CHAR_DICT[characters[i].lower()])\n",
    "    #print(labels)\n",
    "    return labels\n",
    "def prepare_training_data():\n",
    "    \n",
    "    X_train=[]\n",
    "    for i in range(260):\n",
    "        image_name='./chars/image'\n",
    "        image_name+=str(i)+'.jpg'\n",
    "        #print(image_name)\n",
    "        image=cv2.imread(image_name)\n",
    "        \n",
    "        image=resize_image(image)\n",
    "        \n",
    "        #print(image_name,image.shape)\n",
    "        X_train.append(image)\n",
    "    return X_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=prepare_training_data()\n",
    "X_train=np.array(X_train)\n",
    "y_train=prepare_labels()\n",
    "x_valid=X_train[:52]\n",
    "y_valid=y_train[:52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAEHFJREFUeJzt3W+MXNV5x/HfM7O7/g+FuDiuMXWKqNsKqZBYtFVQ66oiIi2VyYsgnDdGreKoCmqRWqkIqQpShRRFJW36hsoIK0ZKIKmAYEVRkwhVIS8iikFpIHED1HKx440dY1ow2Ovdmacv9ppsYO9zxrMzc2f9fD+Stbtz5t555np/c2f23HOOubsA5NNqugAAzSD8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSmhjlg5kZlxMCQ+bu1sv9lnTmN7ObzezHZvaKmd29lH0BGC3r99p+M2tLeknSTZKOSnpW0k53/1GwDWd+YMhGcea/QdIr7n7I3c9JelTSjiXsD8AILSX8myQdWfDz0eq2X2Bmu83sgJkdWMJjARiwpfzBb7G3Fu95W+/ueyTtkXjbD4yTpZz5j0ravODnKyUdW1o5AEZlKeF/VtI1ZvYBM5uSdLuk/YMpC8Cw9f22393nzOxOSd+U1Ja0191/OLDKAAxV3119fT0Yn/mBoRvJRT4Ali/CDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSGunU3cvZyTP1AxInp+JtJ1vxYMZV6sY7mGuHzd1gDNdsYSBlu/DyP+Fz8R2s//NH1+Pn3bLJeAedwiDR9rmgcSbc1OzSeN8XAc78QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU/fw9inq7r9zy6+G2Z48cCdtl8X/DOo/7pL01W9t2uvTyXrjEQN24tsnwyEiTweZvFx97XdjcKpy7Nq16q7bt1ZPPFB784seZH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSWlI/v5kdlvSmpI6kOXffNoiixtHlKzu1bYdefSnc9kz9ppKkJx54Imy//65PhO3Hjv9nfeP7fjnc9i29L2zXXLzg65p4qgHJ3qhtmtXqcNPX345/PR998Kmw/Z//7pb6xs50uG0Gg7jI5w/d/eQA9gNghHjbDyS11PC7pG+Z2XNmtnsQBQEYjaW+7f+wux8zsyskfdvM/svdn154h+pFgRcGYMws6czv7seqryckPSHphkXus8fdt13MfwwElqO+w29ma8xs3fnvJX1E0ouDKgzAcC3lbf8GSU+Y2fn9fNnd/20gVQEYur7D7+6HJP32AGsZa5OqHzM/0Y07u8+UpuVvrQjb162M2zURjamP5wJoFcbjd1WYO78wrb8m668TeEvxNQSvFa4heE3xHeY8mNd/VekChYsfXX1AUoQfSIrwA0kRfiApwg8kRfiBpJi6u1ed+q6+FbYy3LRbv6kkaaLwEuxzZ+I7dKKlqOMurVbhV6C0Cnb59BHdId74XGHfM5NxN+aZaPvCcOEMOPMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFJ0dvYq6i4vTM29uvAS256L+uml1fEM15JHBUyFm54pDKstKl0HEAyF/iXFz/t0Ox7KvHoyHk981dZr6xsv2RpumwFnfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iin7+ntXPv/12Yby+FabunmjHY+5Pz8T94ZqK+urj/+LTham3n306Xn78L/70g2H7T3/6XH3jJevDbTd43M//l3f8Sdj+N3d8NGj9v3DbDDjzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSxX5+M9sr6RZJJ9z92uq2yyV9RdIWSYcl3eburw+vzHFQ35duhRW0Z+Lp5fV2tJS0pLPtwph7q19G+2zh9b1b2PWhl14O2yfPxRcKnHn5YG3bqg/9TrzvVjxRwqpOYU2CdvTc47UWMujlzP9FSTe/67a7JT3l7tdIeqr6GcAyUgy/uz8t6dS7bt4haV/1/T5Jtw64LgBD1u9n/g3uPi1J1dcrBlcSgFEY+rX9ZrZb0u5hPw6AC9Pvmf+4mW2UpOrribo7uvsed9/m7tv6fCwAQ9Bv+PdL2lV9v0vSk4MpB8CoFMNvZo9I+p6krWZ21Mz+XNJnJd1kZi9Luqn6GcAyUvzM7+47a5r+aMC1jLn6DvFWYe76s4WX2LMT8dz6p96MH2D9+utr216LH1o6ty5u91Vh8xaL+9rbFl1IUJhMwArtrfixCxsvYduLA0cASIrwA0kRfiApwg8kRfiBpAg/kBRTd/fK6+ffniyNuC20z87Ec3tftirujvvJ9H/UN166Mdz2WOfSsP1f/yW+futzd94ets8G3XFxB2fZ6cKU6WvDByiuLX7R48wPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0nRz98rq+8X7hRW0J4stF/ejuf+XtstdGh3zgaN8TUEk4WX/y1bt4bttm5N2L5m868ErfGv31yhfbJ+xnJJUjd4budUmE89Ac78QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU/fw9CwblF2aQniqM55+ajfrppVXtwoUC4RTX8bj10qv/jX/wG2H7kVO1izXNm/jfwiPUaxWqiycVl7rBU7dgWfMsOPMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFLFfn4z2yvpFkkn3P3a6rZ7JX1S0s+qu93j7t8YVpHjob5feKYTb+mFl9hOYcD/bGFMvlpRn3X84CsK09dHY+Ln2+M7tLUy3kGgdGZa0grdiudQyKCXM/8XJd28yO3/6O7XVf8u8uADF59i+N39aUmnRlALgBFaymf+O83sB2a218wuG1hFAEai3/A/IOlqSddJmpZ0f90dzWy3mR0wswN9PhaAIegr/O5+3N077t6V9KCkG4L77nH3be6+rd8iAQxeX+E3s4VLv35M0ouDKQfAqPTS1feIpO2S1pvZUUmfkbTdzK7T/HjRw5I+NcQaAQxBMfzuvnORmx8aQi3jzesH5U8WjmKn1Fe+Mh7wP9cudGjPRJ318b5XtuKO/k7wvMt7l7paXb/vwlwDpX1PdAoXWEQXApT+UxLgCABJEX4gKcIPJEX4gaQIP5AU4QeSYuruXgVLdJdGlnYLI3JnZ+Mur5lzhR2smgoaz8TbKl5i2z3+FelGs4ZLak3VP7fCs5J1S519hSMfHdaJQjdhApz5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiAp+vl7Vj+9djsYtipJUS+8JLU78X/DZKv039T/Et2l3u5OYWrvlcXfoPrlx1uFXz/rxstoe2nl8mjz9ky8cQKc+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKXMvdOQO8sEsGBQ/5p45U1/67139oXDb7rH/DtvXKO5zPhf0lUvSbHQhQWFI/NpC+/rZuP0TO7aH7fc9tj9ojfv5Xyss7z1XeHJrgusA1oZbSraiNJfA+HIvzLde4cwPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kV+/nNbLOkhyW9X/NTre9x9y+Y2eWSviJpi6TDkm5z99cL+1q2/fxHgoHtawvP6pJCe2GV7OKsCzMWdcbHI/ZXFBfCLhRXuk7EovNLPO/+2/Ge1Smcu9YE7a3CegM2ST+/ND9TxF+7+29K+l1Jnzaz35J0t6Sn3P0aSU9VPwNYJorhd/dpd3+++v5NSQclbZK0Q9K+6m77JN06rCIBDN4FfeY3sy2Srpf0jKQN7j4tzb9ASLpi0MUBGJ6e5/Azs7WSHpN0l7u/YdbbZyIz2y1pd3/lARiWns78Zjap+eB/yd0fr24+bmYbq/aNkk4stq2773H3be6+bRAFAxiMYvht/hT/kKSD7v75BU37Je2qvt8l6cnBlwdgWHrp6rtR0nclvaCfr6p8j+Y/939V0lWSXpX0cXc/VdjXsu3qmwvW2fZO3J3WsrhLq9WKP0LNFObXDmf2Lh3xwqe30hLcK0rrk4f7j4vzbjye2FqFc5cHxYddkJLZinjfY6zXrj7G8/eI8C+O8I8fxvMDCBF+ICnCDyRF+IGkCD+QFOEHkmKJ7h61o2GzE3GXVbfQnzZbGNpaWqG7FXQFlvp8Skt0zxR2MFtoj4Yrry5dY9Iq9SMWqg9rq++6zYIzP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRT9/r8JRkvFraKc4kjlubxd6683r+6xLw15L1wGsKJweCiN+5cGU52oXdt4tHLdS+0T9dQKlujPgzA8kRfiBpAg/kBThB5Ii/EBShB9IivADSdHP36tuMLa80F9dHJVemh+7sDSaTQSP343HvJeuA5gqXIPQCqY0l6T2RP+/YuE1ApKsHe97NihtdtlOIj84nPmBpAg/kBThB5Ii/EBShB9IivADSRF+IKliJ6yZbZb0sKT3a36y8z3u/gUzu1fSJyX9rLrrPe7+jWEV2jQLxoYDy5F5aeEEs42SNrr782a2TtJzkm6VdJuk0+7+Dz0/mBVntQCwRO7hzDPvKJ753X1a0nT1/ZtmdlDSpqWVB6BpF/SZ38y2SLpe0jPVTXea2Q/MbK+ZXVazzW4zO2BmB5ZUKYCBKr7tf+eOZmslfUfSfe7+uJltkHRS8xPQ/b3mPxr8WWEfvO0HhqzXt/09hd/MJiV9XdI33f3zi7RvkfR1d7+2sB/CDwxZr+Evvu03M5P0kKSDC4Nf/SHwvI9JevFCiwTQnF7+2n+jpO9KekE/X9f4Hkk7JV2n+bf9hyV9qvrjYLQvzvzAkA30bf+gEH5g+Ab2th/AxYnwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+Q1KiX6D4p6X8W/Ly+um0cjWtt41qXRG39GmRtv9rrHUc6nv89D252wN23NVZAYFxrG9e6JGrrV1O18bYfSIrwA0k1Hf49DT9+ZFxrG9e6JGrrVyO1NfqZH0Bzmj7zA2hII+E3s5vN7Mdm9oqZ3d1EDXXM7LCZvWBm3296ibFqGbQTZvbigtsuN7Nvm9nL1ddFl0lrqLZ7zewn1bH7vpn9cUO1bTazfzezg2b2QzP7q+r2Ro9dUFcjx23kb/vNrC3pJUk3SToq6VlJO939RyMtpIaZHZa0zd0b7xM2s9+XdFrSw+dXQzKzz0k65e6frV44L3P3vx2T2u7VBa7cPKTa6laWvkMNHrtBrng9CE2c+W+Q9Iq7H3L3c5IelbSjgTrGnrs/LenUu27eIWlf9f0+zf/yjFxNbWPB3afd/fnq+zclnV9ZutFjF9TViCbCv0nSkQU/H9V4Lfntkr5lZs+Z2e6mi1nEhvMrI1Vfr2i4nncrrtw8Su9aWXpsjl0/K14PWhPhX2w1kXHqcviwu39Q0kclfbp6e4vePCDpas0v4zYt6f4mi6lWln5M0l3u/kaTtSy0SF2NHLcmwn9U0uYFP18p6VgDdSzK3Y9VX09IekLzH1PGyfHzi6RWX080XM873P24u3fcvSvpQTV47KqVpR+T9CV3f7y6ufFjt1hdTR23JsL/rKRrzOwDZjYl6XZJ+xuo4z3MbE31hxiZ2RpJH9H4rT68X9Ku6vtdkp5ssJZfMC4rN9etLK2Gj924rXjdyEU+VVfGP0lqS9rr7veNvIhFmNmvaf5sL82PePxyk7WZ2SOStmt+1NdxSZ+R9DVJX5V0laRXJX3c3Uf+h7ea2rbrAlduHlJtdStLP6MGj90gV7weSD1c4QfkxBV+QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeS+n/FipoyKscwnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x96e9198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[5])\n",
    "print(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "EPOCHS=100\n",
    "BATCH_SIZE=50\n",
    "def Model_Arch(x,prob):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    kernal1 = tf.Variable(tf.truncated_normal(shape = (3,3,3,6),mean = mu,stddev = sigma))\n",
    "    bias1 = tf.Variable(tf.zeros(6))\n",
    "    \n",
    "    \n",
    "    # TODO: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    #conv2d takes input,filter,strides,padding\n",
    "    conv1 = tf.add(tf.nn.conv2d(x,kernal1,strides=[1,1,1,1],padding = 'VALID'),bias1)\n",
    "    #adding bias \n",
    "\n",
    "    \n",
    "    \n",
    "    # TODO: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    \n",
    "    \n",
    "    \n",
    "    conv1 = tf.nn.avg_pool(conv1,ksize = [1,2,2,1],strides = [1,2,2,1],padding = 'VALID')\n",
    "    \n",
    "    first_layer_output = conv1\n",
    "    \n",
    "   \n",
    "    \n",
    "    kernal2 = tf.Variable(tf.truncated_normal(shape = (3,3,6,16),mean = mu,stddev = sigma))\n",
    "    \n",
    "    bias2 = tf.Variable(tf.zeros(16))\n",
    "    conv2 = tf.add(tf.nn.conv2d(first_layer_output,kernal2,strides=[1,2,2,1],padding = 'VALID'),bias2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # TODO: Activation.\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    \n",
    "    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    \n",
    "    \n",
    "    # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
    "    \n",
    "    second_layer_output = conv2\n",
    "    #return second_layer_output\n",
    "    flatted_input = flatten(second_layer_output)\n",
    "    \n",
    "    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    weight1  = tf.Variable(tf.truncated_normal(shape = (576,200),mean = mu,stddev = sigma))\n",
    "    bias3 = tf.Variable(tf.zeros(200))\n",
    "    \n",
    "    output = tf.add(tf.matmul(flatted_input,weight1),bias3)\n",
    "    # TODO: Activation.\n",
    "    output = tf.nn.relu(output)\n",
    "    output = tf.nn.dropout(output, prob)\n",
    "    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    weight2  = tf.Variable(tf.truncated_normal(shape = (200,100),mean = mu,stddev = sigma))\n",
    "    bias4  = tf.Variable(tf.zeros(100))\n",
    "    output2 = tf.add(tf.matmul(output,weight2),bias4)\n",
    "    output2 = tf.nn.relu(output2)\n",
    "    output2 = tf.nn.dropout(output2, prob)\n",
    "    \n",
    "    # TODO: Activation.\n",
    "\n",
    "    # TODO: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    weight3 = tf.Variable(tf.truncated_normal(shape=(100,26),mean = mu,stddev = sigma))\n",
    "    bias5 = tf.Variable(tf.zeros(26))\n",
    "    output3 = tf.add(tf.matmul(output2,weight3),bias5)\n",
    "    logits = output3\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0001\n",
    "x = tf.placeholder(tf.float32, (None,28, 28, 3))\n",
    "prob=tf.placeholder(tf.float32)\n",
    "\n",
    "logits=Model_Arch(x,prob)\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y=tf.one_hot(y,26)\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_operation = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate_model(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y,prob:1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.038\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.000\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.019\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.019\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.038\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.038\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.058\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.096\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.096\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.096\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.096\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.096\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.096\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.115\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.096\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.096\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.115\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.115\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.115\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.154\n",
      "\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.154\n",
      "\n",
      "EPOCH 22 ...\n",
      "Validation Accuracy = 0.173\n",
      "\n",
      "EPOCH 23 ...\n",
      "Validation Accuracy = 0.192\n",
      "\n",
      "EPOCH 24 ...\n",
      "Validation Accuracy = 0.269\n",
      "\n",
      "EPOCH 25 ...\n",
      "Validation Accuracy = 0.327\n",
      "\n",
      "EPOCH 26 ...\n",
      "Validation Accuracy = 0.346\n",
      "\n",
      "EPOCH 27 ...\n",
      "Validation Accuracy = 0.385\n",
      "\n",
      "EPOCH 28 ...\n",
      "Validation Accuracy = 0.385\n",
      "\n",
      "EPOCH 29 ...\n",
      "Validation Accuracy = 0.404\n",
      "\n",
      "EPOCH 30 ...\n",
      "Validation Accuracy = 0.404\n",
      "\n",
      "EPOCH 31 ...\n",
      "Validation Accuracy = 0.423\n",
      "\n",
      "EPOCH 32 ...\n",
      "Validation Accuracy = 0.385\n",
      "\n",
      "EPOCH 33 ...\n",
      "Validation Accuracy = 0.423\n",
      "\n",
      "EPOCH 34 ...\n",
      "Validation Accuracy = 0.481\n",
      "\n",
      "EPOCH 35 ...\n",
      "Validation Accuracy = 0.519\n",
      "\n",
      "EPOCH 36 ...\n",
      "Validation Accuracy = 0.538\n",
      "\n",
      "EPOCH 37 ...\n",
      "Validation Accuracy = 0.538\n",
      "\n",
      "EPOCH 38 ...\n",
      "Validation Accuracy = 0.558\n",
      "\n",
      "EPOCH 39 ...\n",
      "Validation Accuracy = 0.596\n",
      "\n",
      "EPOCH 40 ...\n",
      "Validation Accuracy = 0.635\n",
      "\n",
      "EPOCH 41 ...\n",
      "Validation Accuracy = 0.635\n",
      "\n",
      "EPOCH 42 ...\n",
      "Validation Accuracy = 0.673\n",
      "\n",
      "EPOCH 43 ...\n",
      "Validation Accuracy = 0.673\n",
      "\n",
      "EPOCH 44 ...\n",
      "Validation Accuracy = 0.654\n",
      "\n",
      "EPOCH 45 ...\n",
      "Validation Accuracy = 0.673\n",
      "\n",
      "EPOCH 46 ...\n",
      "Validation Accuracy = 0.712\n",
      "\n",
      "EPOCH 47 ...\n",
      "Validation Accuracy = 0.731\n",
      "\n",
      "EPOCH 48 ...\n",
      "Validation Accuracy = 0.731\n",
      "\n",
      "EPOCH 49 ...\n",
      "Validation Accuracy = 0.731\n",
      "\n",
      "EPOCH 50 ...\n",
      "Validation Accuracy = 0.750\n",
      "\n",
      "EPOCH 51 ...\n",
      "Validation Accuracy = 0.808\n",
      "\n",
      "EPOCH 52 ...\n",
      "Validation Accuracy = 0.808\n",
      "\n",
      "EPOCH 53 ...\n",
      "Validation Accuracy = 0.808\n",
      "\n",
      "EPOCH 54 ...\n",
      "Validation Accuracy = 0.788\n",
      "\n",
      "EPOCH 55 ...\n",
      "Validation Accuracy = 0.808\n",
      "\n",
      "EPOCH 56 ...\n",
      "Validation Accuracy = 0.846\n",
      "\n",
      "EPOCH 57 ...\n",
      "Validation Accuracy = 0.846\n",
      "\n",
      "EPOCH 58 ...\n",
      "Validation Accuracy = 0.885\n",
      "\n",
      "EPOCH 59 ...\n",
      "Validation Accuracy = 0.885\n",
      "\n",
      "EPOCH 60 ...\n",
      "Validation Accuracy = 0.885\n",
      "\n",
      "EPOCH 61 ...\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "EPOCH 62 ...\n",
      "Validation Accuracy = 0.904\n",
      "\n",
      "EPOCH 63 ...\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "EPOCH 64 ...\n",
      "Validation Accuracy = 0.904\n",
      "\n",
      "EPOCH 65 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 66 ...\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "EPOCH 67 ...\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "EPOCH 68 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 69 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 70 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 71 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 72 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 73 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 74 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 75 ...\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "EPOCH 76 ...\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "EPOCH 77 ...\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "EPOCH 78 ...\n",
      "Validation Accuracy = 0.981\n",
      "\n",
      "EPOCH 79 ...\n",
      "Validation Accuracy = 0.981\n",
      "\n",
      "EPOCH 80 ...\n",
      "Validation Accuracy = 0.981\n",
      "\n",
      "EPOCH 81 ...\n",
      "Validation Accuracy = 0.981\n",
      "\n",
      "EPOCH 82 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 83 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 84 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 85 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 86 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 87 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 88 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 89 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 90 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 91 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 92 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 93 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 94 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 95 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 96 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 97 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 98 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 99 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "EPOCH 100 ...\n",
      "Validation Accuracy = 1.000\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y,prob:0.7})\n",
    "            \n",
    "        validation_accuracy = evaluate_model(x_valid, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './CharacterClassifier.ckpt')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.30110851e-03   6.95755472e-03   3.52796726e-03   3.03880312e-03\n",
      "    2.14705971e-04   1.93685270e-03   3.23269353e-03   1.09335117e-03\n",
      "    7.77418783e-04   2.28812136e-02   2.81638175e-04   1.46831770e-03\n",
      "    5.22610009e-01   2.97237956e-03   5.63653884e-03   1.04271842e-03\n",
      "    1.18928691e-02   1.74361956e-03   1.32405999e-04   2.96122773e-04\n",
      "    4.66513168e-03   2.12520421e-01   6.84143975e-02   2.95818760e-03\n",
      "    2.44777370e-03   1.15955800e-01]]\n"
     ]
    }
   ],
   "source": [
    "test_image=cv2.imread('./test/image0.jpg')\n",
    "test_image=resize_image(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    new_saver = tf.train.import_meta_graph('CharacterClassifier.ckpt.meta')\n",
    "    new_saver.restore(sess,tf.train.latest_checkpoint('.'))\n",
    "    test_images_output = sess.run(tf.nn.softmax(logits), feed_dict={x: test_image,prob : 1.0})\n",
    "print(test_images_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\n"
     ]
    }
   ],
   "source": [
    "print(NO_DICT[np.argmax(test_images_output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
